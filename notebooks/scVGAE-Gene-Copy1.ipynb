{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bd56336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.resetwarnings()\n",
    "\n",
    "import scprep\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch_geometric\n",
    "from torch.nn.functional import relu, softplus\n",
    "from torch.nn import Linear, Module, Dropout, MSELoss, CrossEntropyLoss, BatchNorm1d\n",
    "\n",
    "from torch_geometric.nn import GCNConv, GATConv, GraphNorm\n",
    "from torch_geometric.data import Data\n",
    "from torch_sparse import SparseTensor\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import optuna\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "device = 0\n",
    "device = torch.device(\"cuda:{}\".format(device) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "900842c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topX(X):\n",
    "    return X * np.array(X > np.percentile(X, 85), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c170b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj(x):\n",
    "    adj = SparseTensor(\n",
    "        row= torch.tensor(np.array(x.nonzero()))[0], \n",
    "        col= torch.tensor(np.array(x.nonzero()))[1], \n",
    "        sparse_sizes=(x.shape[0], x.shape[0])\n",
    "    ).to(device)\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce615b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(X, metric='linear'):\n",
    "    dist = pairwise_kernels(X, metric=metric)\n",
    "    dist_x = get_topX(dist)\n",
    "    return torch.tensor(X.values, dtype=torch.float).to(device), get_adj(dist_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4e90ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_i(i):\n",
    "    original_ = pd.read_csv('simulation/data.csv', index_col=0)\n",
    "    df_ = pd.read_csv('simulation/drp_{}0.csv'.format(i), index_col=0)\n",
    "    df_.index = [int(i) for i in df_.index]\n",
    "    df_.columns = [int(i) for i in df_.columns]\n",
    "\n",
    "    original_.columns = df_.columns\n",
    "    original_.index = df_.index\n",
    "\n",
    "    n = original_.size\n",
    "    original_val = original_.values.copy()\n",
    "    t = list(np.ndindex(original_.shape))\n",
    "    random.Random(42).shuffle(t)\n",
    "\n",
    "    mask = t[:int(len(t)/10 * i)]\n",
    "\n",
    "    thr = np.sum(np.sign(df_)) > 0\n",
    "    original_ = original_.loc[:, list(thr)]\n",
    "    df_ = df_.loc[:, list(thr)]\n",
    "\n",
    "    # original = original_.values\n",
    "    original = np.log(original_+1)\n",
    "\n",
    "    # df = df_.values\n",
    "    df = np.log(df_+1)\n",
    "\n",
    "    tmp = pd.DataFrame(thr)\n",
    "    remove = [int(i) for i in tmp[tmp[0] == False].index]\n",
    "    mask = [i for i in mask if i[1] not in remove]\n",
    "    \n",
    "\n",
    "    x, adj = get_data(df)\n",
    "    x_t, adj_t = get_data(df.T)\n",
    "    data = torch.tensor(df.values, dtype=torch.float).to(device)\n",
    "    return df, data, original, mask, x, adj, x_t, adj_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "254c5db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, data, original, mask, x, adj, x_t, adj_t = get_data_for_i(1)\n",
    "origin = np.array([original.loc[i] for i in mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa719d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZINBLoss(y_true, y_pred, theta, pi, eps=1e-10):\n",
    "    \"\"\"\n",
    "    Compute the ZINB Loss.\n",
    "    \n",
    "    y_true: Ground truth data.\n",
    "    y_pred: Predicted mean from the model.\n",
    "    theta: Dispersion parameter.\n",
    "    pi: Zero-inflation probability.\n",
    "    eps: Small constant to prevent log(0).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Negative Binomial Loss\n",
    "    nb_terms = -torch.lgamma(y_true + theta) + torch.lgamma(y_true + 1) + torch.lgamma(theta) \\\n",
    "               - theta * torch.log(theta + eps) \\\n",
    "               + theta * torch.log(theta + y_pred + eps) \\\n",
    "               - y_true * torch.log(y_pred + theta + eps) \\\n",
    "               + y_true * torch.log(y_pred + eps)\n",
    "    \n",
    "    # Zero-Inflation\n",
    "    zero_inflated = torch.log(pi + (1 - pi) * torch.pow(1 + y_pred / theta, -theta))\n",
    "    \n",
    "    result = -torch.sum(torch.log(pi + (1 - pi) * torch.pow(1 + y_pred / theta, -theta)) * (y_true < eps).float() \\\n",
    "                        + (1 - (y_true < eps).float()) * nb_terms)\n",
    "    \n",
    "    return torch.round(result, decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91b8b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(x_original, x_recon, z_mean, z_dropout, z_dispersion, alpha):\n",
    "    \"\"\"\n",
    "    Compute the combined loss: ZINB Loss + MSE Loss.\n",
    "    \n",
    "    Parameters:\n",
    "    - x_original: Original data matrix.\n",
    "    - x_recon: Reconstructed matrix from the model.\n",
    "    - z_mean, z_dropout, z_dispersion: Outputs from the model, used for ZINB Loss calculation.\n",
    "    - device: Device to which tensors should be moved before computation.\n",
    "    - lambda_1, lambda_2: Weights for ZINB Loss and MSE Loss respectively.\n",
    "    \n",
    "    Returns:\n",
    "    - total_loss: Combined loss value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute ZINB Loss (assuming ZINBLoss is a properly defined function or class)\n",
    "    zinb_loss = ZINBLoss(x_original, z_mean, z_dispersion, z_dropout)\n",
    "    \n",
    "    # Compute MSE Loss\n",
    "    mse_loss = MSELoss()(x_recon, x_original)\n",
    "    \n",
    "    # Combine the losses\n",
    "    total_loss = alpha * zinb_loss + (1-alpha) * mse_loss\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f3eb80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGAE(Module):\n",
    "    def __init__(\n",
    "        self, trial, input_dim, hidden0, hidden1, hidden2, hidden3, dropout1, dropout2, dropout4\n",
    "    ):\n",
    "        super(VGAE, self).__init__()\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(dropout1)\n",
    "        self.dropout2 = nn.Dropout(dropout2)\n",
    "        self.dropout4 = nn.Dropout(dropout4)\n",
    "        \n",
    "        # Encoder with 2 gat layers\n",
    "        self.gat1 = GCNConv(input_dim, hidden1)\n",
    "        self.gn1 = GraphNorm(hidden1)  # Batch normalization after first gat layer\n",
    "        self.gat2_mean = GCNConv(hidden1, input_dim)\n",
    "        self.gat2_dropout = GCNConv(hidden1, input_dim)\n",
    "        self.gat2_dispersion = GCNConv(hidden1, input_dim)\n",
    "\n",
    "        # Decoder with 2 Linear layers\n",
    "        self.fc1 = Linear(input_dim, hidden2)\n",
    "        self.bn2 = BatchNorm1d(hidden2)  # Batch normalization after first linear layer\n",
    "        self.fc2 = Linear(hidden2, input_dim)\n",
    "        \n",
    "        # gene_recon\n",
    "        self.graph_norm5 = GraphNorm(hidden3)\n",
    "        self.graph_norm8 = GraphNorm(hidden0)\n",
    "        \n",
    "        self.gcn5 = GCNConv(hidden0, hidden3)\n",
    "        self.gcn8 = GCNConv(hidden3, hidden0)\n",
    "\n",
    "        \n",
    "    def encode(self, x, adj):\n",
    "        x = relu(self.gn1(self.gat1(x, adj)))  # Apply ReLU and GraphNorm\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        z_mean = softplus(self.gat2_mean(x, adj.t()))\n",
    "        z_dropout = torch.sigmoid(self.gat2_dropout(x, adj.t()))\n",
    "        z_dispersion = torch.exp(self.gat2_dispersion(x, adj.t()))\n",
    "        return z_mean, z_dropout, z_dispersion\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = relu(self.bn2(self.fc1(z)))  # Apply ReLU and BatchNorm\n",
    "        z = self.dropout2(z)\n",
    "        return torch.sigmoid(self.fc2(z))\n",
    "    \n",
    "    def gene_recon(self, x_t, adj_t):\n",
    "        x_t = self.dropout4(relu(self.graph_norm5(self.gcn5(x_t, adj_t.t()))))\n",
    "        x_t = (relu(self.graph_norm8(self.gcn8(x_t, adj_t.t()))))\n",
    "        return x_t.T\n",
    "    \n",
    "    def forward(self, x, adj, x_t, adj_t, ):\n",
    "        z_mean, z_dropout, z_dispersion = self.encode(x, adj.t())\n",
    "        x_recon = self.decode(z_mean) + self.gene_recon(x_t, adj_t)\n",
    "        return x_recon, z_mean, z_dropout, z_dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e8bdc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    input_dim = df.shape[1]\n",
    "    hidden0 = df.shape[0]\n",
    "    hidden1 = trial.suggest_categorical('hidden1', [128, 256, 512, 1024])\n",
    "    hidden2 = trial.suggest_categorical('hidden2', [128, 256, 512, 1024])\n",
    "    hidden3 = trial.suggest_categorical('hidden3', [128, 256, 512, 1024])\n",
    "    \n",
    "    dropout1 = trial.suggest_categorical(\"dropout1\", [i/10 for i in range(1, 6)])\n",
    "    dropout2 = trial.suggest_categorical(\"dropout2\", [i/10 for i in range(1, 6)])\n",
    "    dropout4 = trial.suggest_categorical(\"dropout4\", [i/10 for i in range(1, 6)])\n",
    "    \n",
    "    alpha = trial.suggest_categorical(\"alpha\", [0.01, 0.05, 0.1, 0.5, 0.9, 0.95, 0.99])\n",
    "    epochs = trial.suggest_categorical('epochs', list(range(500, 10500, 500)))\n",
    "    lr = trial.suggest_categorical(\"lr\", [0.01, 0.001, 0.0001])\n",
    "\n",
    "    model = VGAE(trial, input_dim, hidden0, hidden1, hidden2, hidden3, dropout1, dropout2, dropout4).to(device)\n",
    "    optimizer_name = 'Adam'\n",
    "    optimizer = getattr(torch.optim, optimizer_name)(\n",
    "        model.parameters(), \n",
    "        lr=lr, \n",
    "    )\n",
    "\n",
    "    losses = []\n",
    "    for epoch in tqdm(range(epochs)): \n",
    "        # Forward pass\n",
    "        x_recon, z_mean, z_dropout, z_dispersion = model(x, adj, x_t, adj_t)\n",
    "\n",
    "        # Compute the ZINB Loss using the outputs from the model\n",
    "        loss = compute_loss(x, x_recon, z_mean, z_dispersion, z_dropout, alpha).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "        losses.append(loss.item())\n",
    "#         print(loss.item())\n",
    "\n",
    "    pred = x_recon.cpu().detach().numpy()\n",
    "    pred = pd.DataFrame(pred, columns=df.columns, index=df.index)\n",
    "    predict = np.array([pred.loc[i] for i in mask])\n",
    "    \n",
    "    return mse(origin, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8babe1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 18:04:05,946] Using an existing study with name 'vgae+gene' instead of creating a new one.\n",
      "100%|██████████| 4500/4500 [1:03:35<00:00,  1.18it/s]\n",
      "[I 2023-08-27 19:07:47,215] Trial 2 finished with value: 0.1715514231407323 and parameters: {'alpha': 0.9, 'dropout1': 0.5, 'dropout2': 0.3, 'dropout4': 0.2, 'epochs': 4500, 'hidden1': 128, 'hidden2': 128, 'hidden3': 1024, 'lr': 0.001}. Best is trial 9 with value: 0.1651847071955788.\n",
      "100%|██████████| 3500/3500 [51:26<00:00,  1.13it/s]\n",
      "[I 2023-08-27 19:59:20,545] Trial 12 finished with value: 0.20133110241995775 and parameters: {'alpha': 0.1, 'dropout1': 0.3, 'dropout2': 0.1, 'dropout4': 0.4, 'epochs': 3500, 'hidden1': 1024, 'hidden2': 512, 'hidden3': 1024, 'lr': 0.001}. Best is trial 9 with value: 0.1651847071955788.\n",
      "100%|██████████| 3000/3000 [34:29<00:00,  1.45it/s]\n",
      "[I 2023-08-27 20:33:55,954] Trial 19 finished with value: 0.16486096267556044 and parameters: {'alpha': 0.5, 'dropout1': 0.1, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 3000, 'hidden1': 256, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 19 with value: 0.16486096267556044.\n",
      "100%|██████████| 3000/3000 [35:12<00:00,  1.42it/s]\n",
      "[I 2023-08-27 21:09:14,826] Trial 20 finished with value: 0.17575251313327797 and parameters: {'alpha': 0.5, 'dropout1': 0.1, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 3000, 'hidden1': 256, 'hidden2': 1024, 'hidden3': 512, 'lr': 0.0001}. Best is trial 19 with value: 0.16486096267556044.\n",
      " 87%|████████▋ | 6491/7500 [1:15:24<11:42,  1.44it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 64%|██████▎   | 4139/6500 [59:52<33:55,  1.16it/s]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 41%|████      | 3268/8000 [36:51<53:23,  1.48it/s]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 5000/5000 [56:24<00:00,  1.48it/s]\n",
      "[I 2023-08-28 11:15:17,582] Trial 106 finished with value: 0.1647791543222237 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 5000, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 9000/9000 [1:23:32<00:00,  1.80it/s]\n",
      "[I 2023-08-28 12:38:55,825] Trial 114 finished with value: 0.16972350573439055 and parameters: {'alpha': 0.95, 'dropout1': 0.2, 'dropout2': 0.1, 'dropout4': 0.5, 'epochs': 9000, 'hidden1': 128, 'hidden2': 128, 'hidden3': 128, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 8500/8500 [1:35:52<00:00,  1.48it/s]\n",
      "[I 2023-08-28 14:14:54,825] Trial 120 finished with value: 0.16474715373165513 and parameters: {'alpha': 0.99, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.3, 'epochs': 8500, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 5000/5000 [56:24<00:00,  1.48it/s]\n",
      "[I 2023-08-28 15:11:25,322] Trial 127 finished with value: 0.16376882279217778 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 5000, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 2500/2500 [28:16<00:00,  1.47it/s]\n",
      "[I 2023-08-28 15:39:48,235] Trial 135 finished with value: 0.1645720110517106 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 2500, 'hidden1': 128, 'hidden2': 256, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 1500/1500 [16:55<00:00,  1.48it/s]\n",
      "[I 2023-08-28 15:56:49,522] Trial 138 finished with value: 0.16981128393113099 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 1500, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 4500/4500 [50:45<00:00,  1.48it/s]\n",
      "[I 2023-08-28 16:47:41,385] Trial 141 finished with value: 0.16404556400966902 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.4, 'epochs': 4500, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 6000/6000 [1:07:41<00:00,  1.48it/s]\n",
      "[I 2023-08-28 17:55:28,547] Trial 148 finished with value: 0.16393119805839368 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 6000, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 6000/6000 [1:07:41<00:00,  1.48it/s]\n",
      "[I 2023-08-28 19:03:15,693] Trial 154 finished with value: 0.16716458178687563 and parameters: {'alpha': 0.05, 'dropout1': 0.2, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 6000, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 5000/5000 [56:24<00:00,  1.48it/s]\n",
      "[I 2023-08-28 19:59:46,453] Trial 163 finished with value: 0.16447634734201397 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 5000, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 4500/4500 [50:45<00:00,  1.48it/s]\n",
      "[I 2023-08-28 20:50:38,270] Trial 169 finished with value: 0.16485020806844242 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.4, 'epochs': 4500, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      " 93%|█████████▎| 6016/6500 [1:07:51<05:27,  1.48it/s]"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    storage=\"sqlite:///vgae+gene.sqlite3\",\n",
    "    study_name=\"vgae+gene\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=1000, gc_after_trial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19c0849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9c1aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc55288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8206f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c708b388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e07c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3e9925",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu3",
   "language": "python",
   "name": "gpu3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
