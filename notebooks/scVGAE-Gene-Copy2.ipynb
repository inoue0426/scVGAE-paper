{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bd56336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.resetwarnings()\n",
    "\n",
    "import scprep\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch_geometric\n",
    "from torch.nn.functional import relu, softplus\n",
    "from torch.nn import Linear, Module, Dropout, MSELoss, CrossEntropyLoss, BatchNorm1d\n",
    "\n",
    "from torch_geometric.nn import GCNConv, GATConv, GraphNorm\n",
    "from torch_geometric.data import Data\n",
    "from torch_sparse import SparseTensor\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import optuna\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "device = 0\n",
    "device = torch.device(\"cuda:{}\".format(device) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "900842c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topX(X):\n",
    "    return X * np.array(X > np.percentile(X, 85), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c170b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj(x):\n",
    "    adj = SparseTensor(\n",
    "        row= torch.tensor(np.array(x.nonzero()))[0], \n",
    "        col= torch.tensor(np.array(x.nonzero()))[1], \n",
    "        sparse_sizes=(x.shape[0], x.shape[0])\n",
    "    ).to(device)\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce615b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(X, metric='linear'):\n",
    "    dist = pairwise_kernels(X, metric=metric)\n",
    "    dist_x = get_topX(dist)\n",
    "    return torch.tensor(X.values, dtype=torch.float).to(device), get_adj(dist_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4e90ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_i(i):\n",
    "    original_ = pd.read_csv('simulation/data.csv', index_col=0)\n",
    "    df_ = pd.read_csv('simulation/drp_{}0.csv'.format(i), index_col=0)\n",
    "    df_.index = [int(i) for i in df_.index]\n",
    "    df_.columns = [int(i) for i in df_.columns]\n",
    "\n",
    "    original_.columns = df_.columns\n",
    "    original_.index = df_.index\n",
    "\n",
    "    n = original_.size\n",
    "    original_val = original_.values.copy()\n",
    "    t = list(np.ndindex(original_.shape))\n",
    "    random.Random(42).shuffle(t)\n",
    "\n",
    "    mask = t[:int(len(t)/10 * i)]\n",
    "\n",
    "    thr = np.sum(np.sign(df_)) > 0\n",
    "    original_ = original_.loc[:, list(thr)]\n",
    "    df_ = df_.loc[:, list(thr)]\n",
    "\n",
    "    # original = original_.values\n",
    "    original = np.log(original_+1)\n",
    "\n",
    "    # df = df_.values\n",
    "    df = np.log(df_+1)\n",
    "\n",
    "    tmp = pd.DataFrame(thr)\n",
    "    remove = [int(i) for i in tmp[tmp[0] == False].index]\n",
    "    mask = [i for i in mask if i[1] not in remove]\n",
    "    \n",
    "\n",
    "    x, adj = get_data(df)\n",
    "    x_t, adj_t = get_data(df.T)\n",
    "    data = torch.tensor(df.values, dtype=torch.float).to(device)\n",
    "    return df, data, original, mask, x, adj, x_t, adj_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "254c5db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, data, original, mask, x, adj, x_t, adj_t = get_data_for_i(1)\n",
    "origin = np.array([original.loc[i] for i in mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa719d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZINBLoss(y_true, y_pred, theta, pi, eps=1e-10):\n",
    "    \"\"\"\n",
    "    Compute the ZINB Loss.\n",
    "    \n",
    "    y_true: Ground truth data.\n",
    "    y_pred: Predicted mean from the model.\n",
    "    theta: Dispersion parameter.\n",
    "    pi: Zero-inflation probability.\n",
    "    eps: Small constant to prevent log(0).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Negative Binomial Loss\n",
    "    nb_terms = -torch.lgamma(y_true + theta) + torch.lgamma(y_true + 1) + torch.lgamma(theta) \\\n",
    "               - theta * torch.log(theta + eps) \\\n",
    "               + theta * torch.log(theta + y_pred + eps) \\\n",
    "               - y_true * torch.log(y_pred + theta + eps) \\\n",
    "               + y_true * torch.log(y_pred + eps)\n",
    "    \n",
    "    # Zero-Inflation\n",
    "    zero_inflated = torch.log(pi + (1 - pi) * torch.pow(1 + y_pred / theta, -theta))\n",
    "    \n",
    "    result = -torch.sum(torch.log(pi + (1 - pi) * torch.pow(1 + y_pred / theta, -theta)) * (y_true < eps).float() \\\n",
    "                        + (1 - (y_true < eps).float()) * nb_terms)\n",
    "    \n",
    "    return torch.round(result, decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91b8b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(x_original, x_recon, z_mean, z_dropout, z_dispersion, alpha):\n",
    "    \"\"\"\n",
    "    Compute the combined loss: ZINB Loss + MSE Loss.\n",
    "    \n",
    "    Parameters:\n",
    "    - x_original: Original data matrix.\n",
    "    - x_recon: Reconstructed matrix from the model.\n",
    "    - z_mean, z_dropout, z_dispersion: Outputs from the model, used for ZINB Loss calculation.\n",
    "    - device: Device to which tensors should be moved before computation.\n",
    "    - lambda_1, lambda_2: Weights for ZINB Loss and MSE Loss respectively.\n",
    "    \n",
    "    Returns:\n",
    "    - total_loss: Combined loss value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute ZINB Loss (assuming ZINBLoss is a properly defined function or class)\n",
    "    zinb_loss = ZINBLoss(x_original, z_mean, z_dispersion, z_dropout)\n",
    "    \n",
    "    # Compute MSE Loss\n",
    "    mse_loss = MSELoss()(x_recon, x_original)\n",
    "    \n",
    "    # Combine the losses\n",
    "    total_loss = alpha * zinb_loss + (1-alpha) * mse_loss\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f3eb80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGAE(Module):\n",
    "    def __init__(\n",
    "        self, trial, input_dim, hidden0, hidden1, hidden2, hidden3, dropout1, dropout2, dropout4\n",
    "    ):\n",
    "        super(VGAE, self).__init__()\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(dropout1)\n",
    "        self.dropout2 = nn.Dropout(dropout2)\n",
    "        self.dropout4 = nn.Dropout(dropout4)\n",
    "        \n",
    "        # Encoder with 2 gat layers\n",
    "        self.gat1 = GCNConv(input_dim, hidden1)\n",
    "        self.gn1 = GraphNorm(hidden1)  # Batch normalization after first gat layer\n",
    "        self.gat2_mean = GCNConv(hidden1, input_dim)\n",
    "        self.gat2_dropout = GCNConv(hidden1, input_dim)\n",
    "        self.gat2_dispersion = GCNConv(hidden1, input_dim)\n",
    "\n",
    "        # Decoder with 2 Linear layers\n",
    "        self.fc1 = Linear(input_dim, hidden2)\n",
    "        self.bn2 = BatchNorm1d(hidden2)  # Batch normalization after first linear layer\n",
    "        self.fc2 = Linear(hidden2, input_dim)\n",
    "        \n",
    "        # gene_recon\n",
    "        self.graph_norm5 = GraphNorm(hidden3)\n",
    "        self.graph_norm8 = GraphNorm(hidden0)\n",
    "        \n",
    "        self.gcn5 = GCNConv(hidden0, hidden3)\n",
    "        self.gcn8 = GCNConv(hidden3, hidden0)\n",
    "\n",
    "        \n",
    "    def encode(self, x, adj):\n",
    "        x = relu(self.gn1(self.gat1(x, adj)))  # Apply ReLU and GraphNorm\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        z_mean = softplus(self.gat2_mean(x, adj.t()))\n",
    "        z_dropout = torch.sigmoid(self.gat2_dropout(x, adj.t()))\n",
    "        z_dispersion = torch.exp(self.gat2_dispersion(x, adj.t()))\n",
    "        return z_mean, z_dropout, z_dispersion\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = relu(self.bn2(self.fc1(z)))  # Apply ReLU and BatchNorm\n",
    "        z = self.dropout2(z)\n",
    "        return torch.sigmoid(self.fc2(z))\n",
    "    \n",
    "    def gene_recon(self, x_t, adj_t):\n",
    "        x_t = self.dropout4(relu(self.graph_norm5(self.gcn5(x_t, adj_t.t()))))\n",
    "        x_t = (relu(self.graph_norm8(self.gcn8(x_t, adj_t.t()))))\n",
    "        return x_t.T\n",
    "    \n",
    "    def forward(self, x, adj, x_t, adj_t, ):\n",
    "        z_mean, z_dropout, z_dispersion = self.encode(x, adj.t())\n",
    "        x_recon = self.decode(z_mean) + self.gene_recon(x_t, adj_t)\n",
    "        return x_recon, z_mean, z_dropout, z_dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e8bdc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    input_dim = df.shape[1]\n",
    "    hidden0 = df.shape[0]\n",
    "    hidden1 = trial.suggest_categorical('hidden1', [128, 256, 512, 1024])\n",
    "    hidden2 = trial.suggest_categorical('hidden2', [128, 256, 512, 1024])\n",
    "    hidden3 = trial.suggest_categorical('hidden3', [128, 256, 512, 1024])\n",
    "    \n",
    "    dropout1 = trial.suggest_categorical(\"dropout1\", [i/10 for i in range(1, 6)])\n",
    "    dropout2 = trial.suggest_categorical(\"dropout2\", [i/10 for i in range(1, 6)])\n",
    "    dropout4 = trial.suggest_categorical(\"dropout4\", [i/10 for i in range(1, 6)])\n",
    "    \n",
    "    alpha = trial.suggest_categorical(\"alpha\", [0.01, 0.05, 0.1, 0.5, 0.9, 0.95, 0.99])\n",
    "    epochs = trial.suggest_categorical('epochs', list(range(500, 10500, 500)))\n",
    "    lr = trial.suggest_categorical(\"lr\", [0.01, 0.001, 0.0001])\n",
    "\n",
    "    model = VGAE(trial, input_dim, hidden0, hidden1, hidden2, hidden3, dropout1, dropout2, dropout4).to(device)\n",
    "    optimizer_name = 'Adam'\n",
    "    optimizer = getattr(torch.optim, optimizer_name)(\n",
    "        model.parameters(), \n",
    "        lr=lr, \n",
    "    )\n",
    "\n",
    "    losses = []\n",
    "    for epoch in tqdm(range(epochs)): \n",
    "        # Forward pass\n",
    "        x_recon, z_mean, z_dropout, z_dispersion = model(x, adj, x_t, adj_t)\n",
    "\n",
    "        # Compute the ZINB Loss using the outputs from the model\n",
    "        loss = compute_loss(x, x_recon, z_mean, z_dispersion, z_dropout, alpha).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "        losses.append(loss.item())\n",
    "#         print(loss.item())\n",
    "\n",
    "    pred = x_recon.cpu().detach().numpy()\n",
    "    pred = pd.DataFrame(pred, columns=df.columns, index=df.index)\n",
    "    predict = np.array([pred.loc[i] for i in mask])\n",
    "    \n",
    "    return mse(origin, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8babe1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 13:50:38,541] Using an existing study with name 'vgae+gene' instead of creating a new one.\n",
      "100%|██████████| 5000/5000 [26:44<00:00,  3.12it/s]\n",
      "[I 2023-08-28 14:17:30,854] Trial 124 finished with value: 0.16431959193707216 and parameters: {'alpha': 0.1, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 5000, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 5000/5000 [26:44<00:00,  3.12it/s]\n",
      "[I 2023-08-28 14:44:23,383] Trial 128 finished with value: 0.16364057755263844 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 5000, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 5000/5000 [26:44<00:00,  3.12it/s]\n",
      "[I 2023-08-28 15:11:15,983] Trial 131 finished with value: 0.164527633340191 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 5000, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 4500/4500 [24:11<00:00,  3.10it/s]\n",
      "[I 2023-08-28 15:35:34,616] Trial 134 finished with value: 0.1655008821904324 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 4500, 'hidden1': 128, 'hidden2': 256, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 1500/1500 [08:01<00:00,  3.12it/s]\n",
      "[I 2023-08-28 15:43:43,481] Trial 137 finished with value: 0.17156243236191857 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 1500, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 4500/4500 [24:04<00:00,  3.12it/s]\n",
      "[I 2023-08-28 16:07:55,421] Trial 140 finished with value: 0.16440458731116853 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 4500, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 1000/1000 [05:20<00:00,  3.12it/s]\n",
      "[I 2023-08-28 16:13:24,279] Trial 143 finished with value: 0.1656006854470275 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.4, 'epochs': 1000, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 4500/4500 [24:04<00:00,  3.11it/s]\n",
      "[I 2023-08-28 16:37:36,818] Trial 145 finished with value: 0.16691538395167943 and parameters: {'alpha': 0.99, 'dropout1': 0.3, 'dropout2': 0.5, 'dropout4': 0.1, 'epochs': 4500, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 5000/5000 [26:45<00:00,  3.11it/s]\n",
      "[I 2023-08-28 17:04:29,910] Trial 147 finished with value: 0.16425344156074692 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 5000, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 6000/6000 [32:06<00:00,  3.11it/s]\n",
      "[I 2023-08-28 17:36:44,077] Trial 149 finished with value: 0.16412836455118415 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 6000, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 5000/5000 [26:45<00:00,  3.11it/s]\n",
      "[I 2023-08-28 18:03:36,825] Trial 152 finished with value: 0.16436569059638675 and parameters: {'alpha': 0.05, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 5000, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 6000/6000 [27:46<00:00,  3.60it/s]\n",
      "[I 2023-08-28 18:31:31,147] Trial 156 finished with value: 0.1726489654648411 and parameters: {'alpha': 0.95, 'dropout1': 0.2, 'dropout2': 0.3, 'dropout4': 0.1, 'epochs': 6000, 'hidden1': 128, 'hidden2': 512, 'hidden3': 128, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 2000/2000 [10:42<00:00,  3.12it/s]\n",
      "[I 2023-08-28 18:42:20,588] Trial 159 finished with value: 0.16693798903179097 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 2000, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 7000/7000 [37:28<00:00,  3.11it/s]\n",
      "[I 2023-08-28 19:19:56,248] Trial 162 finished with value: 0.16729746622823477 and parameters: {'alpha': 0.95, 'dropout1': 0.1, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 7000, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 5000/5000 [27:00<00:00,  3.09it/s]\n",
      "[I 2023-08-28 19:47:04,105] Trial 164 finished with value: 0.16416365823593412 and parameters: {'alpha': 0.9, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 5000, 'hidden1': 256, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 4500/4500 [24:04<00:00,  3.11it/s]\n",
      "[I 2023-08-28 20:11:16,241] Trial 167 finished with value: 0.1644271649472476 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.4, 'epochs': 4500, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 4500/4500 [21:43<00:00,  3.45it/s]\n",
      "[I 2023-08-28 20:33:07,173] Trial 171 finished with value: 0.1645737001312458 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.4, 'epochs': 4500, 'hidden1': 128, 'hidden2': 128, 'hidden3': 256, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 6500/6500 [34:49<00:00,  3.11it/s]\n",
      "[I 2023-08-28 21:08:03,993] Trial 174 finished with value: 0.1646827675546558 and parameters: {'alpha': 0.95, 'dropout1': 0.4, 'dropout2': 0.1, 'dropout4': 0.1, 'epochs': 6500, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 5500/5500 [29:27<00:00,  3.11it/s]\n",
      "[I 2023-08-28 21:37:39,017] Trial 176 finished with value: 0.16477104982972524 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 5500, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      " 78%|███████▊  | 3889/5000 [20:50<05:57,  3.11it/s]"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    storage=\"sqlite:///vgae+gene.sqlite3\",\n",
    "    study_name=\"vgae+gene\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=1000, gc_after_trial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19c0849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9c1aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc55288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8206f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c708b388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e07c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3e9925",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
