{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76147f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, normalized_mutual_info_score\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "from sklearn.decomposition import PCA, SparsePCA, KernelPCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from rpy2.robjects import r, pandas2ri\n",
    "from rpy2.robjects.vectors import StrVector\n",
    "\n",
    "pandas2ri.activate()\n",
    "\n",
    "import magic\n",
    "import scprep\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# from sklearnex import patch_sklearn\n",
    "# patch_sklearn()\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "\n",
    "# r('''library(Seurat)''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63485fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_metrics(pred, labels):\n",
    "    ari_res = []\n",
    "    ami_res = []\n",
    "    nmi_res = []\n",
    "\n",
    "    # Assuming you have the necessary R libraries and the rpy2 interface to use the Seurat method\n",
    "    try:\n",
    "        r.assign(\"data\", pred.T)\n",
    "        seurat = r('''\n",
    "            countsData = data.frame(data)\n",
    "            pbmc <- CreateSeuratObject(counts = countsData, project = \"thal_single_cell\", min.cells = 1, min.features = 1)\n",
    "            pbmc <- FindVariableFeatures(pbmc, selection.method = \"vst\", verbose=FALSE)\n",
    "            all.genes <- rownames(pbmc)\n",
    "            pbmc <- ScaleData(pbmc, features = all.genes, verbose=FALSE)\n",
    "            pbmc <- RunPCA(pbmc, verbose=FALSE)\n",
    "            pbmc <- FindNeighbors(pbmc, verbose=FALSE)\n",
    "            pbmc <- FindClusters(pbmc, verbose=FALSE)\n",
    "            Idents(pbmc)\n",
    "        ''')\n",
    "        ari_res.append(adjusted_rand_score(labels, seurat))\n",
    "        ami_res.append(adjusted_mutual_info_score(labels, seurat))\n",
    "        nmi_res.append(normalized_mutual_info_score(labels, seurat))\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    pred_ = KMeans(n_clusters=len(np.unique(labels)), random_state=42, n_init='auto').fit_predict(pred)\n",
    "\n",
    "    ari_res.append(adjusted_rand_score(labels, pred_))\n",
    "    ami_res.append(adjusted_mutual_info_score(labels, pred_))\n",
    "    nmi_res.append(normalized_mutual_info_score(labels, pred_))\n",
    "\n",
    "    warnings.filterwarnings(\"error\")\n",
    "\n",
    "    affinities = ['cosine', 'linear', 'poly']\n",
    "\n",
    "    for i in affinities:\n",
    "        try:\n",
    "            pred_ = SpectralClustering(\n",
    "                n_clusters=len(np.unique(labels)), \n",
    "                random_state=42, \n",
    "                affinity=i\n",
    "            ).fit_predict(pred)\n",
    "            ari_res.append(adjusted_rand_score(labels, pred_))\n",
    "            ami_res.append(adjusted_mutual_info_score(labels, pred_))\n",
    "            nmi_res.append(normalized_mutual_info_score(labels, pred_))\n",
    "        except:\n",
    "            ari_res.append(0)\n",
    "            ami_res.append(0)\n",
    "            nmi_res.append(0)\n",
    "\n",
    "    warnings.resetwarnings()\n",
    "    \n",
    "    return max(ari_res), max(ami_res), max(nmi_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd528efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(i):\n",
    "    df = pd.read_csv('../../data/{}/data.csv.gz'.format(i), index_col=0)\n",
    "    tmp = np.sign(df)\n",
    "    cols = (np.sum(tmp) > int((df.shape[0])*0.05))\n",
    "    rows = (np.sum(tmp, axis=1) > int((df.shape[1])*0.05))\n",
    "    df = np.log(df.loc[rows, cols] + 1)\n",
    "    df_norm = df.copy()\n",
    "    df_norm = scprep.normalize.library_size_normalize(df_norm)    \n",
    "    df_norm = scprep.transform.sqrt(df_norm)\n",
    "    X_norm = pd.DataFrame(df_norm, columns=df.columns)\n",
    "    labels = df.index\n",
    "    return X_norm, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b03893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = [\n",
    "    'manno', 'Xu', 'brosens', 'jakel', 'Fujii', 'loureiro', \n",
    "    'carey', 'hcabm40k', 'jiang', 'Selewa'\n",
    "]\n",
    "\n",
    "res = []\n",
    "for i in tqdm(dir_list):\n",
    "    X_norm, labels = get_data(i)\n",
    "    pred = magic.MAGIC().fit_transform(X_norm)\n",
    "    res.append(get_cluster_metrics(pred, labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
