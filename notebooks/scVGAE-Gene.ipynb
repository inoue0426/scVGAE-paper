{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bd56336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.resetwarnings()\n",
    "\n",
    "import scprep\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch_geometric\n",
    "from torch.nn.functional import relu, softplus\n",
    "from torch.nn import Linear, Module, Dropout, MSELoss, CrossEntropyLoss, BatchNorm1d\n",
    "\n",
    "from torch_geometric.nn import GCNConv, GATConv, GraphNorm\n",
    "from torch_geometric.data import Data\n",
    "from torch_sparse import SparseTensor\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import optuna\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "device = 1\n",
    "device = torch.device(\"cuda:{}\".format(device) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "900842c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topX(X):\n",
    "    return X * np.array(X > np.percentile(X, 85), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c170b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj(x):\n",
    "    adj = SparseTensor(\n",
    "        row= torch.tensor(np.array(x.nonzero()))[0], \n",
    "        col= torch.tensor(np.array(x.nonzero()))[1], \n",
    "        sparse_sizes=(x.shape[0], x.shape[0])\n",
    "    ).to(device)\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce615b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(X, metric='linear'):\n",
    "    dist = pairwise_kernels(X, metric=metric)\n",
    "    dist_x = get_topX(dist)\n",
    "    return torch.tensor(X.values, dtype=torch.float).to(device), get_adj(dist_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4e90ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_i(i):\n",
    "    original_ = pd.read_csv('simulation/data.csv', index_col=0)\n",
    "    df_ = pd.read_csv('simulation/drp_{}0.csv'.format(i), index_col=0)\n",
    "    df_.index = [int(i) for i in df_.index]\n",
    "    df_.columns = [int(i) for i in df_.columns]\n",
    "\n",
    "    original_.columns = df_.columns\n",
    "    original_.index = df_.index\n",
    "\n",
    "    n = original_.size\n",
    "    original_val = original_.values.copy()\n",
    "    t = list(np.ndindex(original_.shape))\n",
    "    random.Random(42).shuffle(t)\n",
    "\n",
    "    mask = t[:int(len(t)/10 * i)]\n",
    "\n",
    "    thr = np.sum(np.sign(df_)) > 0\n",
    "    original_ = original_.loc[:, list(thr)]\n",
    "    df_ = df_.loc[:, list(thr)]\n",
    "\n",
    "    # original = original_.values\n",
    "    original = np.log(original_+1)\n",
    "\n",
    "    # df = df_.values\n",
    "    df = np.log(df_+1)\n",
    "\n",
    "    tmp = pd.DataFrame(thr)\n",
    "    remove = [int(i) for i in tmp[tmp[0] == False].index]\n",
    "    mask = [i for i in mask if i[1] not in remove]\n",
    "    \n",
    "\n",
    "    x, adj = get_data(df)\n",
    "    x_t, adj_t = get_data(df.T)\n",
    "    data = torch.tensor(df.values, dtype=torch.float).to(device)\n",
    "    return df, data, original, mask, x, adj, x_t, adj_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "254c5db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, data, original, mask, x, adj, x_t, adj_t = get_data_for_i(1)\n",
    "origin = np.array([original.loc[i] for i in mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa719d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZINBLoss(y_true, y_pred, theta, pi, eps=1e-10):\n",
    "    \"\"\"\n",
    "    Compute the ZINB Loss.\n",
    "    \n",
    "    y_true: Ground truth data.\n",
    "    y_pred: Predicted mean from the model.\n",
    "    theta: Dispersion parameter.\n",
    "    pi: Zero-inflation probability.\n",
    "    eps: Small constant to prevent log(0).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Negative Binomial Loss\n",
    "    nb_terms = -torch.lgamma(y_true + theta) + torch.lgamma(y_true + 1) + torch.lgamma(theta) \\\n",
    "               - theta * torch.log(theta + eps) \\\n",
    "               + theta * torch.log(theta + y_pred + eps) \\\n",
    "               - y_true * torch.log(y_pred + theta + eps) \\\n",
    "               + y_true * torch.log(y_pred + eps)\n",
    "    \n",
    "    # Zero-Inflation\n",
    "    zero_inflated = torch.log(pi + (1 - pi) * torch.pow(1 + y_pred / theta, -theta))\n",
    "    \n",
    "    result = -torch.sum(torch.log(pi + (1 - pi) * torch.pow(1 + y_pred / theta, -theta)) * (y_true < eps).float() \\\n",
    "                        + (1 - (y_true < eps).float()) * nb_terms)\n",
    "    \n",
    "    return torch.round(result, decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91b8b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(x_original, x_recon, z_mean, z_dropout, z_dispersion, alpha):\n",
    "    \"\"\"\n",
    "    Compute the combined loss: ZINB Loss + MSE Loss.\n",
    "    \n",
    "    Parameters:\n",
    "    - x_original: Original data matrix.\n",
    "    - x_recon: Reconstructed matrix from the model.\n",
    "    - z_mean, z_dropout, z_dispersion: Outputs from the model, used for ZINB Loss calculation.\n",
    "    - device: Device to which tensors should be moved before computation.\n",
    "    - lambda_1, lambda_2: Weights for ZINB Loss and MSE Loss respectively.\n",
    "    \n",
    "    Returns:\n",
    "    - total_loss: Combined loss value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute ZINB Loss (assuming ZINBLoss is a properly defined function or class)\n",
    "    zinb_loss = ZINBLoss(x_original, z_mean, z_dispersion, z_dropout)\n",
    "    \n",
    "    # Compute MSE Loss\n",
    "    mse_loss = MSELoss()(x_recon, x_original)\n",
    "    \n",
    "    # Combine the losses\n",
    "    total_loss = alpha * zinb_loss + (1-alpha) * mse_loss\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f3eb80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGAE(Module):\n",
    "    def __init__(\n",
    "        self, trial, input_dim, hidden0, hidden1, hidden2, hidden3, dropout1, dropout2, dropout4\n",
    "    ):\n",
    "        super(VGAE, self).__init__()\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(dropout1)\n",
    "        self.dropout2 = nn.Dropout(dropout2)\n",
    "        self.dropout4 = nn.Dropout(dropout4)\n",
    "        \n",
    "        # Encoder with 2 gat layers\n",
    "        self.gat1 = GCNConv(input_dim, hidden1)\n",
    "        self.gn1 = GraphNorm(hidden1)  # Batch normalization after first gat layer\n",
    "        self.gat2_mean = GCNConv(hidden1, input_dim)\n",
    "        self.gat2_dropout = GCNConv(hidden1, input_dim)\n",
    "        self.gat2_dispersion = GCNConv(hidden1, input_dim)\n",
    "\n",
    "        # Decoder with 2 Linear layers\n",
    "        self.fc1 = Linear(input_dim, hidden2)\n",
    "        self.bn2 = BatchNorm1d(hidden2)  # Batch normalization after first linear layer\n",
    "        self.fc2 = Linear(hidden2, input_dim)\n",
    "        \n",
    "        # gene_recon\n",
    "        self.graph_norm5 = GraphNorm(hidden3)\n",
    "        self.graph_norm8 = GraphNorm(hidden0)\n",
    "        \n",
    "        self.gcn5 = GCNConv(hidden0, hidden3)\n",
    "        self.gcn8 = GCNConv(hidden3, hidden0)\n",
    "\n",
    "        \n",
    "    def encode(self, x, adj):\n",
    "        x = relu(self.gn1(self.gat1(x, adj)))  # Apply ReLU and GraphNorm\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        z_mean = softplus(self.gat2_mean(x, adj.t()))\n",
    "        z_dropout = torch.sigmoid(self.gat2_dropout(x, adj.t()))\n",
    "        z_dispersion = torch.exp(self.gat2_dispersion(x, adj.t()))\n",
    "        return z_mean, z_dropout, z_dispersion\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = relu(self.bn2(self.fc1(z)))  # Apply ReLU and BatchNorm\n",
    "        z = self.dropout2(z)\n",
    "        return torch.sigmoid(self.fc2(z))\n",
    "    \n",
    "    def gene_recon(self, x_t, adj_t):\n",
    "        x_t = self.dropout4(relu(self.graph_norm5(self.gcn5(x_t, adj_t.t()))))\n",
    "        x_t = (relu(self.graph_norm8(self.gcn8(x_t, adj_t.t()))))\n",
    "        return x_t.T\n",
    "    \n",
    "    def forward(self, x, adj, x_t, adj_t, ):\n",
    "        z_mean, z_dropout, z_dispersion = self.encode(x, adj.t())\n",
    "        x_recon = self.decode(z_mean) + self.gene_recon(x_t, adj_t)\n",
    "        return x_recon, z_mean, z_dropout, z_dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e8bdc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    input_dim = df.shape[1]\n",
    "    hidden0 = df.shape[0]\n",
    "    hidden1 = trial.suggest_categorical('hidden1', [128, 256, 512, 1024])\n",
    "    hidden2 = trial.suggest_categorical('hidden2', [128, 256, 512, 1024])\n",
    "    hidden3 = trial.suggest_categorical('hidden3', [128, 256, 512, 1024])\n",
    "    \n",
    "    dropout1 = trial.suggest_categorical(\"dropout1\", [i/10 for i in range(1, 6)])\n",
    "    dropout2 = trial.suggest_categorical(\"dropout2\", [i/10 for i in range(1, 6)])\n",
    "    dropout4 = trial.suggest_categorical(\"dropout4\", [i/10 for i in range(1, 6)])\n",
    "    \n",
    "    alpha = trial.suggest_categorical(\"alpha\", [0.01, 0.05, 0.1, 0.5, 0.9, 0.95, 0.99])\n",
    "    epochs = trial.suggest_categorical('epochs', list(range(500, 10500, 500)))\n",
    "    lr = trial.suggest_categorical(\"lr\", [0.01, 0.001, 0.0001])\n",
    "\n",
    "    model = VGAE(trial, input_dim, hidden0, hidden1, hidden2, hidden3, dropout1, dropout2, dropout4).to(device)\n",
    "    optimizer_name = 'Adam'\n",
    "    optimizer = getattr(torch.optim, optimizer_name)(\n",
    "        model.parameters(), \n",
    "        lr=lr, \n",
    "    )\n",
    "\n",
    "    losses = []\n",
    "    for epoch in tqdm(range(epochs)): \n",
    "        # Forward pass\n",
    "        x_recon, z_mean, z_dropout, z_dispersion = model(x, adj, x_t, adj_t)\n",
    "\n",
    "        # Compute the ZINB Loss using the outputs from the model\n",
    "        loss = compute_loss(x, x_recon, z_mean, z_dispersion, z_dropout, alpha).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "        losses.append(loss.item())\n",
    "#         print(loss.item())\n",
    "\n",
    "    pred = x_recon.cpu().detach().numpy()\n",
    "    pred = pd.DataFrame(pred, columns=df.columns, index=df.index)\n",
    "    predict = np.array([pred.loc[i] for i in mask])\n",
    "    \n",
    "    return mse(origin, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8babe1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-27 17:59:26,049] Using an existing study with name 'vgae+gene' instead of creating a new one.\n",
      "100%|██████████| 1500/1500 [10:35<00:00,  2.36it/s]\n",
      "[I 2023-08-27 18:10:11,424] Trial 1 finished with value: 0.16624249025948834 and parameters: {'alpha': 0.95, 'dropout1': 0.5, 'dropout2': 0.3, 'dropout4': 0.5, 'epochs': 1500, 'hidden1': 512, 'hidden2': 128, 'hidden3': 512, 'lr': 0.001}. Best is trial 1 with value: 0.16624249025948834.\n",
      "100%|██████████| 1000/1000 [08:34<00:00,  1.95it/s]\n",
      "[I 2023-08-27 18:18:55,681] Trial 3 finished with value: 0.16850725924752574 and parameters: {'alpha': 0.9, 'dropout1': 0.5, 'dropout2': 0.5, 'dropout4': 0.3, 'epochs': 1000, 'hidden1': 512, 'hidden2': 512, 'hidden3': 1024, 'lr': 0.01}. Best is trial 1 with value: 0.16624249025948834.\n",
      "100%|██████████| 2500/2500 [22:03<00:00,  1.89it/s]\n",
      "[I 2023-08-27 18:41:09,484] Trial 4 finished with value: 0.1997190744366809 and parameters: {'alpha': 0.01, 'dropout1': 0.4, 'dropout2': 0.1, 'dropout4': 0.5, 'epochs': 2500, 'hidden1': 1024, 'hidden2': 512, 'hidden3': 1024, 'lr': 0.01}. Best is trial 1 with value: 0.16624249025948834.\n",
      "100%|██████████| 7000/7000 [41:07<00:00,  2.84it/s]\n",
      "[I 2023-08-27 19:22:26,967] Trial 7 finished with value: 0.17163510412902286 and parameters: {'alpha': 0.1, 'dropout1': 0.2, 'dropout2': 0.2, 'dropout4': 0.2, 'epochs': 7000, 'hidden1': 128, 'hidden2': 256, 'hidden3': 128, 'lr': 0.0001}. Best is trial 9 with value: 0.1651847071955788.\n",
      "100%|██████████| 2500/2500 [16:19<00:00,  2.55it/s]\n",
      "[I 2023-08-27 19:38:57,275] Trial 13 finished with value: 0.18694487227382006 and parameters: {'alpha': 0.99, 'dropout1': 0.2, 'dropout2': 0.2, 'dropout4': 0.2, 'epochs': 2500, 'hidden1': 1024, 'hidden2': 1024, 'hidden3': 128, 'lr': 0.001}. Best is trial 9 with value: 0.1651847071955788.\n",
      "100%|██████████| 10000/10000 [1:11:51<00:00,  2.32it/s]\n",
      "[I 2023-08-27 20:50:58,634] Trial 14 finished with value: 0.19305439009511322 and parameters: {'alpha': 0.5, 'dropout1': 0.3, 'dropout2': 0.1, 'dropout4': 0.1, 'epochs': 10000, 'hidden1': 256, 'hidden2': 1024, 'hidden3': 512, 'lr': 0.0001}. Best is trial 19 with value: 0.16486096267556044.\n",
      "100%|██████████| 8000/8000 [55:47<00:00,  2.39it/s]\n",
      "[I 2023-08-27 21:46:55,497] Trial 23 finished with value: 0.17646283297551987 and parameters: {'alpha': 0.5, 'dropout1': 0.1, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 8000, 'hidden1': 256, 'hidden2': 256, 'hidden3': 512, 'lr': 0.0001}. Best is trial 26 with value: 0.1646193269976962.\n",
      " 46%|████▌     | 3420/7500 [23:38<28:10,  2.41it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 30%|██▉       | 2217/7500 [18:46<44:44,  1.97it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 64%|██████▍   | 4814/7500 [40:45<22:43,  1.97it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 40%|████      | 2624/6500 [22:53<33:48,  1.91it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 85%|████████▌ | 5551/6500 [48:25<08:16,  1.91it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 20%|██        | 1705/8500 [11:44<46:49,  2.42it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 54%|█████▎    | 4559/8500 [31:23<27:07,  2.42it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 5000/5000 [34:24<00:00,  2.42it/s]\n",
      "[I 2023-08-28 06:29:11,114] Trial 76 finished with value: 0.1638879194557653 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 5000, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 71 with value: 0.16368900422712457.\n",
      "  0%|          | 10/5000 [00:04<34:10,  2.43it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 38%|███▊      | 1900/5000 [13:04<21:18,  2.42it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 84%|████████▍ | 4222/5000 [29:03<05:21,  2.42it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|█████████▉| 7992/8000 [55:02<00:03,  2.42it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 38%|███▊      | 2109/5500 [14:30<23:18,  2.42it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 75%|███████▍  | 4099/5500 [28:13<09:38,  2.42it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 43%|████▎     | 2161/5000 [14:52<19:32,  2.42it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 5000/5000 [34:26<00:00,  2.42it/s]\n",
      "[I 2023-08-28 10:55:26,894] Trial 107 finished with value: 0.1642504403038011 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 5000, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 71 with value: 0.16368900422712457.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [1:05:26<00:00,  2.42it/s]\n",
      "[I 2023-08-28 12:01:02,771] Trial 111 finished with value: 0.1684085529736224 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.5, 'epochs': 9500, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      " 29%|██▉       | 1012/3500 [06:57<17:09,  2.42it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 5000/5000 [34:27<00:00,  2.42it/s]\n",
      "[I 2023-08-28 18:16:09,415] Trial 153 finished with value: 0.1649287927531361 and parameters: {'alpha': 0.05, 'dropout1': 0.2, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 5000, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 500/500 [03:26<00:00,  2.42it/s]\n",
      "[I 2023-08-28 18:19:45,865] Trial 157 finished with value: 0.21511581984547573 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 500, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 2000/2000 [13:46<00:00,  2.42it/s]\n",
      "[I 2023-08-28 18:33:42,826] Trial 158 finished with value: 0.16754890717379828 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 2000, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 7000/7000 [48:14<00:00,  2.42it/s]\n",
      "[I 2023-08-28 19:22:06,989] Trial 160 finished with value: 0.16556109074167766 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 7000, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 5000/5000 [34:41<00:00,  2.40it/s]\n",
      "[I 2023-08-28 19:56:58,185] Trial 165 finished with value: 0.16515755051982156 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 5000, 'hidden1': 256, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 4500/4500 [30:58<00:00,  2.42it/s]\n",
      "[I 2023-08-28 20:28:06,714] Trial 168 finished with value: 0.1641887329394601 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.4, 'epochs': 4500, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 6500/6500 [44:45<00:00,  2.42it/s]\n",
      "[I 2023-08-28 21:13:02,138] Trial 172 finished with value: 0.16507851884658672 and parameters: {'alpha': 0.95, 'dropout1': 0.4, 'dropout2': 0.1, 'dropout4': 0.4, 'epochs': 6500, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      "100%|██████████| 5000/5000 [34:25<00:00,  2.42it/s]\n",
      "[I 2023-08-28 21:47:38,262] Trial 178 finished with value: 0.16376156764973185 and parameters: {'alpha': 0.95, 'dropout1': 0.3, 'dropout2': 0.2, 'dropout4': 0.1, 'epochs': 5000, 'hidden1': 128, 'hidden2': 128, 'hidden3': 512, 'lr': 0.0001}. Best is trial 108 with value: 0.16330715039059435.\n",
      " 30%|███       | 1525/5000 [10:51<24:43,  2.34it/s]"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    storage=\"sqlite:///vgae+gene.sqlite3\",\n",
    "    study_name=\"vgae+gene\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=1000, gc_after_trial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19c0849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9c1aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc55288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8206f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c708b388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e07c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3e9925",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu1",
   "language": "python",
   "name": "gpu1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
